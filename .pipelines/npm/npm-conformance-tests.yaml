trigger:
  - master

variables:
  - name: VNET_NAME
    value: npm-vnet
  - name: NUM_PARALLEL_JOBS_FOR_STRESS_TEST
    value: "3"

jobs:
  - job: setup
    displayName: "Configure Test Environment"
    pool:
      name: $(BUILD_POOL_NAME_DEFAULT)
      demands:
        - agent.os -equals Linux
        - Role -equals Build
    steps:
      - checkout: self

      - script: |
          go version
          go env
          which go
          echo $PATH
          mkdir -p '$(GOBIN)'
          mkdir -p '$(GOPATH)/pkg'
          BUILD_NUMBER=$(Build.BuildNumber)
          RG=conf-$(echo "npm-`date "+%Y-%m-%d-%M-%S"`")
          TAG=$(make version)-conformance-test
          echo "Resource group: $RG"
          echo "Image tag: $TAG"

          echo "##vso[task.setvariable variable=RESOURCE_GROUP;isOutput=true;]$RG"
          echo "##vso[task.setvariable variable=TAG;isOutput=true;]$TAG"

        name: "EnvironmentalVariables"
        displayName: "Set environmental variables"
        condition: always()

  - job: k8se2e
    displayName: "Build Kubernetes Test Suite"
    pool:
      name: $(BUILD_POOL_NAME_DEFAULT)
      demands:
        - agent.os -equals Linux
        - Role -equals Build
    steps:
      - checkout: self

      - script: git clone https://github.com/huntergregory/kubernetes.git
        displayName: "Clone Kubernetes Repo"
      - bash: |
          cd kubernetes
          git checkout skip-namespace-cleanup
          export PATH=$PATH:/usr/local/go/bin/
          make WHAT=test/e2e/e2e.test
        displayName: "Build Kubernetes e2e.test"
      - publish: $(System.DefaultWorkingDirectory)/kubernetes/_output/local/bin/linux/amd64
        artifact: Test

  - job: Create_Cluster_and_Run_Test
    timeoutInMinutes: 360
    displayName: "Run Kubernetes Network Policy Test Suite"
    strategy:
      matrix:
        ws22-1:
          AZURE_CLUSTER: "conf-ws22-1"
          PROFILE: "v2-default"
        ws22-2:
          AZURE_CLUSTER: "conf-ws22-2"
          PROFILE: "v2-default"
        ws22-3:
          AZURE_CLUSTER: "conf-ws22-3"
          PROFILE: "v2-default"
        ws22-4:
          AZURE_CLUSTER: "conf-ws22-4"
          PROFILE: "v2-default"
        ws22-5:
          AZURE_CLUSTER: "conf-ws22-5"
          PROFILE: "v2-default"
        ws22-6:
          AZURE_CLUSTER: "conf-ws22-6"
          PROFILE: "v2-default"
        ws22-7:
          AZURE_CLUSTER: "conf-ws22-7"
          PROFILE: "v2-default"
        ws22-8:
          AZURE_CLUSTER: "conf-ws22-8"
          PROFILE: "v2-default"
        ws22-9:
          AZURE_CLUSTER: "conf-ws22-9"
          PROFILE: "v2-default"
        ws22-10:
          AZURE_CLUSTER: "conf-ws22-10"
          PROFILE: "v2-default"
        ws22-11:
          AZURE_CLUSTER: "conf-ws22-11"
          PROFILE: "v2-default"
        ws22-12:
          AZURE_CLUSTER: "conf-ws22-12"
          PROFILE: "v2-default"
        ws22-13:
          AZURE_CLUSTER: "conf-ws22-13"
          PROFILE: "v2-default"
        ws22-14:
          AZURE_CLUSTER: "conf-ws22-14"
          PROFILE: "v2-default"
        ws22-15:
          AZURE_CLUSTER: "conf-ws22-15"
          PROFILE: "v2-default"
        ws22-16:
          AZURE_CLUSTER: "conf-ws22-16"
          PROFILE: "v2-default"
        ws22-17:
          AZURE_CLUSTER: "conf-ws22-17"
          PROFILE: "v2-default"
        ws22-18:
          AZURE_CLUSTER: "conf-ws22-18"
          PROFILE: "v2-default"
        ws22-19:
          AZURE_CLUSTER: "conf-ws22-19"
          PROFILE: "v2-default"
        ws22-20:
          AZURE_CLUSTER: "conf-ws22-20"
          PROFILE: "v2-default"
        ws22-21:
          AZURE_CLUSTER: "conf-ws22-21"
          PROFILE: "v2-default"
        ws22-22:
          AZURE_CLUSTER: "conf-ws22-22"
          PROFILE: "v2-default"
        ws22-23:
          AZURE_CLUSTER: "conf-ws22-23"
          PROFILE: "v2-default"
        ws22-24:
          AZURE_CLUSTER: "conf-ws22-24"
          PROFILE: "v2-default"
        ws22-25:
          AZURE_CLUSTER: "conf-ws22-25"
          PROFILE: "v2-default"
        ws22-26:
          AZURE_CLUSTER: "conf-ws22-26"
          PROFILE: "v2-default"
        ws22-27:
          AZURE_CLUSTER: "conf-ws22-27"
          PROFILE: "v2-default"
        ws22-28:
          AZURE_CLUSTER: "conf-ws22-28"
          PROFILE: "v2-default"
        ws22-29:
          AZURE_CLUSTER: "conf-ws22-29"
          PROFILE: "v2-default"
        ws22-30:
          AZURE_CLUSTER: "conf-ws22-30"
          PROFILE: "v2-default"
    pool:
      name: $(BUILD_POOL_NAME_DEFAULT)
      demands:
        - agent.os -equals Linux
        - Role -equals Build
    dependsOn: [setup, k8se2e]
    variables:
      RESOURCE_GROUP: $[ dependencies.setup.outputs['EnvironmentalVariables.RESOURCE_GROUP'] ]
      TAG: $[ dependencies.setup.outputs['EnvironmentalVariables.TAG'] ]
      FQDN: empty
    steps:
      - checkout: none
      - download: current
        artifact: Test

      - task: AzureCLI@2
        displayName: "Deploy"
        inputs:
          azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
          scriptType: "bash"
          scriptLocation: "inlineScript"
          inlineScript: |
            LOCATION=eastus
            az group create -n $(RESOURCE_GROUP) -l $(LOCATION) -o table
            echo created RG $(RESOURCE_GROUP) in $(LOCATION)
            az version

      - task: AzureCLI@2
        displayName: "Deploy NPM to Test Cluster"
        inputs:
          azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
          scriptType: "bash"
          scriptLocation: "inlineScript"
          inlineScript: |
            if [[ $(AZURE_CLUSTER) == *ws22* ]] # * is used for pattern matching
            then
              az extension add --name aks-preview
              az extension update --name aks-preview

              # Enable Microsoft.ContainerService/AKSWindows2022Preview
              az feature register --namespace Microsoft.ContainerService --name AKSWindows2022Preview
              az provider register -n Microsoft.ContainerService

              echo "creating WS22 Cluster";
              az aks create \
                  --resource-group $(RESOURCE_GROUP) \
                  --name $(AZURE_CLUSTER) \
                  --generate-ssh-keys \
                  --windows-admin-username e2eadmin \
                  --windows-admin-password alpha@numeric!password2 \
                  --network-plugin azure \
                  --vm-set-type VirtualMachineScaleSets \
                  --kubernetes-version v1.23 \
                  --node-count 1

              # don't schedule anything on the linux system pool
              echo "Updating $(AZURE_CLUSTER) to not schedule anything on linux pool..."
              az aks nodepool update \
                --cluster-name $(AZURE_CLUSTER) \
                -g $(RESOURCE_GROUP) \
                -n nodepool1 \
                --node-taints CriticalAddonsOnly=true:NoSchedule

              echo "Adding Windows nodepool to $(AZURE_CLUSTER) to group $(RESOURCE_GROUP)"
              az aks nodepool add \
                  --resource-group $(RESOURCE_GROUP) \
                  --cluster-name $(AZURE_CLUSTER) \
                  --name awin22 \
                  --os-type Windows \
                  --os-sku Windows2022 \
                  --node-vm-size Standard_DS3_v2 \
                  --node-count 3 \
                  --max-pods 120
            else
              echo "Creating Linux Cluster"; 
              az aks create --no-ssh-key \
              --resource-group $(RESOURCE_GROUP) \
              --name $(AZURE_CLUSTER) \
              --network-plugin azure
            fi

            echo Cluster $(AZURE_CLUSTER)
            echo Resource $(RESOURCE_GROUP)

            az aks get-credentials -n $(AZURE_CLUSTER) -g $(RESOURCE_GROUP) --file ./kubeconfig
            # get kubectl 
            curl -LO https://dl.k8s.io/release/v1.20.0/bin/linux/amd64/kubectl
            chmod +x kubectl

            # deploy hns debugger
            curl -LO https://strgaccfornpmwin.blob.core.windows.net/hns-vfp-repro/hns-debugger.yaml
            ./kubectl --kubeconfig=./kubeconfig apply -f hns-debugger.yaml
            echo "sleeping 10 min after applying hns debugger"
            sleep $((10 * 60))

            # deploy azure-npm
            ./kubectl --kubeconfig=./kubeconfig apply -f https://raw.githubusercontent.com/Azure/azure-container-networking/master/npm/azure-npm.yaml

            # deploy azure-npm-win
            ./kubectl --kubeconfig=./kubeconfig apply -f https://raw.githubusercontent.com/Azure/azure-container-networking/master/npm/examples/windows/azure-npm.yaml

            # swap NPM profile with one specified as parameter
            ./kubectl --kubeconfig=./kubeconfig apply -f https://raw.githubusercontent.com/Azure/azure-container-networking/master/npm/profiles/$(PROFILE).yaml
            ./kubectl --kubeconfig=./kubeconfig rollout restart ds azure-npm -n kube-system
            # not necessary because we only use the one profile
            # ./kubectl --kubeconfig=./kubeconfig rollout restart ds azure-npm-win -n kube-system

            ./kubectl --kubeconfig=./kubeconfig describe daemonset azure-npm -n kube-system
            ./kubectl --kubeconfig=./kubeconfig describe daemonset azure-npm-win -n kube-system

            FQDN=`az aks show -n $(AZURE_CLUSTER) -g $(RESOURCE_GROUP) --query fqdn -o tsv`
            echo "##vso[task.setvariable variable=FQDN]$FQDN"
      - bash: |
          echo "sleeping 3 minutes to allow NPM pods to restart"
          sleep 180

          echo 'all pods status to start'
          ./kubectl --kubeconfig=./kubeconfig get pod -A -owide
          echo 'all pod resources to start'
          ./kubectl --kubeconfig=./kubeconfig top pod -A
          echo 'all node resources to start'
          ./kubectl --kubeconfig=./kubeconfig top node

          ## create the output folder and include the kubeconfig there
          npmLogsFolder=$(System.DefaultWorkingDirectory)/npmLogs_$(AZURE_CLUSTER)
          mkdir -p $npmLogsFolder
          cp ./kubeconfig $npmLogsFolder/kubeconfig

          ## Run all Conformance tests in the background
          echo $FQDN
          chmod +x $(Pipeline.Workspace)/Test/e2e.test
          nomatch1="should enforce policy based on PodSelector or NamespaceSelector"
          nomatch2="should enforce policy based on NamespaceSelector with MatchExpressions using default ns label"
          nomatch3="should enforce policy based on PodSelector and NamespaceSelector"
          nomatch4="should enforce policy based on Multiple PodSelectors and NamespaceSelectors"
          cidrExcept1="should ensure an IP overlapping both IPBlock.CIDR and IPBlock.Except is allowed"
          cidrExcept2="should enforce except clause while egress access to server in CIDR block"
          namedPorts="named port"
          wrongK8sVersion="Netpol API"
          toSkip="\[LinuxOnly\]|$nomatch1|$nomatch2|$nomatch3|$nomatch4|$cidrExcept1|$cidrExcept2|$namedPorts|$wrongK8sVersion|SCTP"
          runConformance () {
              $(Pipeline.Workspace)/Test/e2e.test --provider=local --allowed-not-ready-nodes=1 --kubeconfig=./kubeconfig --node-os-distro=windows --ginkgo.skip="$toSkip" --ginkgo.focus="NetworkPolicy" --delete-namespace=false
              # there can't be a command after e2e.test because the exit code is important
          }

          # run the conformance test and write the output to stdout and a file
          echo "STARTING conformance"
          runConformance > $npmLogsFolder/conformance-results
          exitCode=$?
          echo "FINISHED conformance"

          echo 'all pods status at end'
          ./kubectl --kubeconfig=./kubeconfig get pod -A -owide
          echo 'all pod resources at end'
          ./kubectl --kubeconfig=./kubeconfig top pod -A
          echo 'all node resources at end'
          ./kubectl --kubeconfig=./kubeconfig top node

          # capture logs after
          npmPodList=`kubectl --kubeconfig=./kubeconfig get pods -n kube-system | grep npm | awk '{print $1}'`
          echo "Found NPM pods: $npmPodList"
          for npmPod in $npmPodList; do
              ./kubectl --kubeconfig=./kubeconfig logs -n kube-system $npmPod > $npmLogsFolder/$npmPod-logs.txt
          done

          exit $exitCode
        displayName: "Run Test Suite and Get Logs"

      - publish: $(System.DefaultWorkingDirectory)/npmLogs_$(AZURE_CLUSTER)
        condition: always()
        artifact: NpmLogs_$(AZURE_CLUSTER)

  - job: clean_up
    displayName: "Cleanup"
    pool:
      name: $(BUILD_POOL_NAME_DEFAULT)
      demands:
        - agent.os -equals Linux
        - Role -equals Build
    dependsOn:
      [Create_Cluster_and_Run_Test, setup]
    variables:
      RESOURCE_GROUP: $[ dependencies.setup.outputs['EnvironmentalVariables.RESOURCE_GROUP'] ]
    steps:
      - checkout: none
      - task: AzureCLI@2
        displayName: "Delete Test Cluster Resource Group"
        inputs:
          azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
          scriptType: "bash"
          scriptLocation: "inlineScript"
          inlineScript: |
            echo Deleting $(RESOURCE_GROUP)
            az group delete -n $(RESOURCE_GROUP) --yes
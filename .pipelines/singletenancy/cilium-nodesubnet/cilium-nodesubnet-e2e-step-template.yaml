parameters:
  name: ""
  clusterName: ""
  scaleup: ""

steps:
  - task: PythonScript@0
    inputs:
      scriptSource: 'inline' # 'filePath' | 'inline'. Required. Script source. Default: filePath.
      arguments: --resource-group MC_${{ parameters.clusterName }}_${{ parameters.clusterName }}_$(REGION_AKS_CLUSTER_TEST) --secondary-config-count ${{ parameters.scaleup }}
      script: |
          import json
          import subprocess
          import argparse

          parser = argparse.ArgumentParser(description="Update IP configuration for VMSS.")
          parser.add_argument("--resource-group", required=True, help="The resource group of the VMSS.")
          parser.add_argument("--secondary-config-count", type=int, required=True, help="The count of secondary IP configurations.")
          args = parser.parse_args()
          resource_group = args.resource_group
          secondary_config_count = args.secondary_config_count

          command = f"az vmss list -g {resource_group} --query '[0].name' -o tsv"
          result = subprocess.run(command, shell=True, capture_output=True, text=True)

          if result.returncode == 0:
              vmss_name = result.stdout.strip()
          else:
              raise Exception(f"Command failed with error: {result.stderr}")

          command = f"az vmss show -g {resource_group} -n {vmss_name}"
          result = subprocess.run(command, shell=True, capture_output=True, text=True)

          if result.returncode == 0:
              vmss_info = json.loads(result.stdout)
          else:
              raise Exception(f"Command failed with error: {result.stderr}")

          used_ip_config_names = []    
          secondary_configs = []

          if "virtualMachineProfile" in vmss_info and "networkProfile" in vmss_info["virtualMachineProfile"]:
              network_profile = vmss_info["virtualMachineProfile"]["networkProfile"]
              if "networkInterfaceConfigurations" in network_profile:
                  for nic_config in network_profile["networkInterfaceConfigurations"]:
                      primary_ip_config = None

                      if "ipConfigurations" in nic_config:
                          for ip_config in nic_config["ipConfigurations"]:
                              if "name" in ip_config:
                                  used_ip_config_names.append(ip_config["name"])

                              if "primary" in ip_config and ip_config["primary"]:
                                  primary_ip_config = ip_config

                          if primary_ip_config is not None:        
                              for i in range(2, secondary_config_count + 2):
                                  ip_config = primary_ip_config.copy()
                                  if f"ipconfig{i}" not in used_ip_config_names:
                                      ip_config["name"] = f"ipconfig{i}"
                                      ip_config["primary"] = False
                                      used_ip_config_names.append(ip_config["name"])
                                      secondary_configs.append(ip_config)

                          nic_config["ipConfigurations"].extend(secondary_configs)

                                  
              command = f"az vmss update -g {resource_group} -n {vmss_name} --set virtualMachineProfile.networkProfile='{json.dumps(network_profile)}'"
              print("Command to update VMSS: ", command)
              result = subprocess.run(command, shell=True)
              if result.returncode != 0:
                  raise Exception(f"Command failed with error: {result.stderr}")

              command = f"az vmss update-instances -g {resource_group} -n {vmss_name} --instance-ids '*'"
              print("Command to update VMSS instances: ", command)
              result = subprocess.run(command, shell=True)
              if result.returncode != 0:
                  raise Exception(f"Command failed with error: {result.stderr}")      

  - bash: |
      echo $UID
      sudo rm -rf $(System.DefaultWorkingDirectory)/*
    displayName: "Set up OS environment"

  - checkout: self

  - bash: |
      go version
      go env
      mkdir -p '$(GOBIN)'
      mkdir -p '$(GOPATH)/pkg'
      mkdir -p '$(modulePath)'
      echo '##vso[task.prependpath]$(GOBIN)'
      echo '##vso[task.prependpath]$(GOROOT)/bin'
    name: "GoEnv"
    displayName: "Set up the Go environment"

  - task: KubectlInstaller@0
    inputs:
      kubectlVersion: latest

  - task: AzureCLI@2
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        make -C ./hack/aks set-kubeconf AZCLI=az CLUSTER=${{ parameters.clusterName }}
        ls -lah
        pwd
        kubectl cluster-info
        kubectl get po -owide -A
        echo "install Cilium ${CILIUM_VERSION_TAG}"
        export DIR=${CILIUM_VERSION_TAG%.*}
        echo "installing files from ${DIR}"
        echo "deploy Cilium ConfigMap"
        kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-config/cilium-config.yaml
        # Passes Cilium image to daemonset and deployment
        kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-agent/files
        kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-operator/files

        envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY}' < test/integration/manifests/cilium/v${DIR}/cilium-agent/templates/daemonset.yaml | kubectl apply -f -
        envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY}' < test/integration/manifests/cilium/v${DIR}/cilium-operator/templates/deployment.yaml | kubectl apply -f -
        kubectl get po -owide -A
    name: "installCilium"
    displayName: "Install Cilium"

  - template: ../../templates/cilium-cli.yaml

  - script: |
      echo "Start Azilium E2E Tests"
      kubectl get po -owide -A
      sudo -E env "PATH=$PATH" make test-load SCALE_UP=32 OS_TYPE=linux VALIDATE_STATEFILE=true INSTALL_CNS=true INSTALL_CNS_NODESUBNET=true AZURE_IPAM_VERSION=$(make azure-ipam-version) CNS_VERSION=$(make cns-version) CLEANUP=true
    retryCountOnTaskFailure: 3
    name: "aziliumTest"
    displayName: "Run Azilium E2E"

  - script: |
      kubectl get po -owide -A
      echo "Waiting < 2 minutes for cilium to be ready"
      # Ensure Cilium is ready Xm\Xs
      cilium status --wait --wait-duration 2m
    retryCountOnTaskFailure: 3
    name: "CiliumStatus"
    displayName: "Cilium Status"

  - task: AzureCLI@1
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        kubectl get po -owide -A
        clusterName=${{ parameters.clusterName }}
        echo "Restarting nodes"
        for val in $(az vmss list -g MC_${clusterName}_${clusterName}_$(REGION_AKS_CLUSTER_TEST) --query "[].name" -o tsv); do
          make -C ./hack/aks restart-vmss AZCLI=az CLUSTER=${clusterName} REGION=$(REGION_AKS_CLUSTER_TEST) VMSS_NAME=${val}
        done
    displayName: "Restart Nodes"

  - task: AzureCLI@1
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        cd test/integration/load

        # Scale Cluster Up/Down to confirm functioning CNS
        ITERATIONS=2 SCALE_UP=${{ parameters.scaleup }} OS_TYPE=linux go test -count 1 -timeout 30m -tags load -run ^TestLoad$
        kubectl get pods -owide -A

        cd ../../..
        echo "Validating Node Restart"
        make test-validate-state OS_TYPE=linux RESTART_CASE=true
        kubectl delete ns load-test
    displayName: "Validate Node Restart"
    retryCountOnTaskFailure: 3

  - script: |
      echo "Run Cilium Connectivity Tests"
      cilium status
      cilium connectivity test --connect-timeout 4s --request-timeout 30s --test '!pod-to-pod-encryption,!node-to-node-encryption' --force-deploy
      ns=`kubectl get ns | grep cilium-test | awk '{print $1}'`
      echo "##vso[task.setvariable variable=ciliumNamespace]$ns"
    retryCountOnTaskFailure: 3
    name: "ciliumConnectivityTests"
    displayName: "Run Cilium Connectivity Tests"

  - script: |
      echo "validate pod IP assignment and check systemd-networkd restart"
      kubectl get pod -owide -A
      # Deleting echo-external-node deployment until cilium version matches TODO. https://github.com/cilium/cilium-cli/issues/67 is addressing the change.
      # Saves 17 minutes
      kubectl delete deploy -n $(ciliumNamespace) echo-external-node
      make test-validate-state
      echo "delete cilium connectivity test resources and re-validate state"
      kubectl delete ns $(ciliumNamespace)
      kubectl get pod -owide -A
      make test-validate-state
    name: "validatePods"
    displayName: "Validate Pods"

  - script: |
      echo "Run wireserver and metadata connectivity Tests"
      bash test/network/wireserver_metadata_test.sh
    retryCountOnTaskFailure: 3
    name: "WireserverMetadataConnectivityTests"
    displayName: "Run Wireserver and Metadata Connectivity Tests"

  - script: |
      cd hack/scripts
      chmod +x async-delete-test.sh
      ./async-delete-test.sh
      if ! [ -z $(kubectl -n kube-system get ds  azure-cns | grep non-existing) ]; then
        kubectl -n kube-system patch daemonset azure-cns --type json -p='[{"op": "remove", "path": "/spec/template/spec/nodeSelector/non-existing"}]'
      fi
    name: "testAsyncDelete"
    displayName: "Verify Async Delete when CNS is down"

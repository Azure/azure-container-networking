parameters:
  name: ""
  clusterName: ""
  scaleup: ""

steps:
  - task: KubectlInstaller@0
    inputs:
      kubectlVersion: latest

  - task: AzureCLI@2
    displayName: "Install Cilium on AKS Dualstack Overlay"
    env:
      AZCLI: az
      CLUSTER: ${{ parameters.clusterName }}
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        make -C ./hack/aks set-kubeconf
        ls -lah
        pwd
        kubectl cluster-info
        kubectl get po -owide -A
        echo "install Cilium ${CILIUM_DUALSTACK_VERSION}"
        export DIR=$(echo ${CILIUM_DUALSTACK_VERSION#v} | cut -d. -f1,2)
        echo "installing files from ${DIR}"
        echo "deploy Cilium ConfigMap"
        kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-config/cilium-config-dualstack.yaml
        # Passes Cilium image to daemonset and deployment
        kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-agent/files
        kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-operator/files

        export CILIUM_VERSION_TAG=${CILIUM_DUALSTACK_VERSION}
        export IPV6_HP_BPF_VERSION=$(make ipv6-hp-bpf-version)
        echo "install Cilium ${CILIUM_DUALSTACK_VERSION} onto Overlay Cluster"
        envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY},${IPV6_HP_BPF_VERSION}' < test/integration/manifests/cilium/v${DIR}/cilium-agent/templates/daemonset-dualstack.yaml | kubectl apply -f -
        envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY}' < test/integration/manifests/cilium/v${DIR}/cilium-operator/templates/deployment.yaml | kubectl apply -f -
        kubectl get po -owide -A

  - template: ../../templates/cilium-cli.yaml

  - script: |
      echo "Start Azilium E2E Tests on Overlay Cluster"
      sudo -E env "PATH=$PATH" make test-load AZURE_IPAM_VERSION=$(make azure-ipam-version) CNS_VERSION=$(make cns-version)
    retryCountOnTaskFailure: 3
    displayName: "Run Azilium E2E on AKS Overlay"
    env:
      SCALE_UP: 32
      OS_TYPE: linux
      CNI_TYPE: cilium_dualstack
      VALIDATE_STATEFILE: true
      INSTALL_CNS: true
      INSTALL_OVERLAY: true
      CLEANUP: true

  - script: |
      kubectl get pods -A
      echo "Waiting < 2 minutes for cilium to be ready"
      # Ensure Cilium is ready Xm\Xs
      cilium status --wait --wait-duration 2m
    retryCountOnTaskFailure: 3
    displayName: "Cilium Status"

  - task: AzureCLI@2
    displayName: "Restart Nodes"
    env:
      AZCLI: az
      CLUSTER: ${{ parameters.clusterName }}
      RESOURCE_GROUP: "MC_${{ parameters.clusterName }}_${{ parameters.clusterName }}_$(REGION_AKS_CLUSTER_TEST)"
      REGION: $(REGION_AKS_CLUSTER_TEST)
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e
        kubectl get po -owide -A
        echo "Restarting nodes"
        for val in $(az vmss list -g "$RESOURCE_GROUP" --query "[].name" -o tsv); do
          make -C ./hack/aks restart-vmss VMSS_NAME=${val}
        done

  - task: AzureCLI@2
    displayName: "Validate Node Restart"
    retryCountOnTaskFailure: 3
    env:
      ITERATIONS: 2
      SCALE_UP: ${{ parameters.scaleup }}
      OS_TYPE: linux
      RESTART_CASE: true
      CNI_TYPE: cilium_dualstack
    inputs:
      azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
      scriptLocation: "inlineScript"
      scriptType: "bash"
      addSpnToEnvironment: true
      inlineScript: |
        set -e

        pushd test/integration/load
          # Scale Cluster Up/Down to confirm functioning CNS
          go test -count 1 -timeout 30m -tags load -run ^TestLoad$
          kubectl get pods -owide -A
        popd

        echo "Validating Node Restart"
        make test-validate-state
        kubectl delete ns load-test

  - script: |
      set -e
      echo "Run Cilium Connectivity Tests"
      cilium status
      cilium connectivity test --connect-timeout 4s --request-timeout 30s --test '!pod-to-pod-encryption,!node-to-node-encryption,!no-unexpected-packet-drops' --force-deploy
      ns=`kubectl get ns | grep cilium-test | awk '{print $1}'`
      echo "##vso[task.setvariable variable=ciliumNamespace]$ns"
    retryCountOnTaskFailure: 3
    displayName: "Run Cilium Connectivity Tests"

  - script: |
      set -e
      kubectl get po -owide -A
      cd test/integration/datapath
      echo "Dualstack Overlay Linux datapath IPv6 test"
      go test -count=1 datapath_linux_test.go -timeout 3m -tags connection -run ^TestDatapathLinux$ -tags=connection,integration -isDualStack=true
      echo "Dualstack Overlay Linux datapath IPv4 test"
      go test -count=1 datapath_linux_test.go -timeout 3m -tags connection -run ^TestDatapathLinux$ -tags=connection,integration
    retryCountOnTaskFailure: 3
    displayName: "DualStack Overlay Linux Tests"

  - script: |
      echo "validate pod IP assignment and check systemd-networkd restart"
      kubectl get pod -owide -A
      # Deleting echo-external-node deployment until cilium version matches TODO. https://github.com/cilium/cilium-cli/issues/67 is addressing the change.
      # Saves 17 minutes
      kubectl delete deploy -n "$CILIUM_NS" echo-external-node
      cd test/integration/load
      CNI_TYPE=cilium_dualstack go test -timeout 30m -tags load -run ^TestValidateState$
      echo "delete cilium connectivity test resources and re-validate state"
      kubectl delete ns "$CILIUM_NS"
      kubectl get pod -owide -A
      go test -timeout 30m -tags load -run ^TestValidateState$
    displayName: "Validate Pods"
    env:
      CILIUM_NS: $(ciliumNamespace)
      CNI_TYPE: cilium_dualstack

  - script: |
      echo "Run wireserver and metadata connectivity Tests"
      bash test/network/wireserver_metadata_test.sh
    retryCountOnTaskFailure: 3
    displayName: "Run Wireserver and Metadata Connectivity Tests"

  - script: |
      cd hack/scripts
      chmod +x async-delete-test.sh
      ./async-delete-test.sh
      if ! [ -z $(kubectl -n kube-system get ds  azure-cns | grep non-existing) ]; then
        kubectl -n kube-system patch daemonset azure-cns --type json -p='[{"op": "remove", "path": "/spec/template/spec/nodeSelector/non-existing"}]'
      fi
    displayName: "Verify Async Delete when CNS is down"

